{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "o5famy7lur8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dependencies installed successfully\n"
     ]
    }
   ],
   "source": [
    "# Install dependencies\n",
    "import subprocess\n",
    "import sys\n",
    "\n",
    "try:\n",
    "    subprocess.run(\n",
    "        [\"uv\", \"pip\", \"install\", \"-r\", \"requirements.txt\"],\n",
    "        capture_output=True,\n",
    "        text=True,\n",
    "        check=True\n",
    "    )\n",
    "    print(\"Dependencies installed successfully\")\n",
    "except (subprocess.CalledProcessError, FileNotFoundError):\n",
    "    # Fallback to pip if uv is not available\n",
    "    subprocess.run(\n",
    "        [sys.executable, \"-m\", \"pip\", \"install\", \"-r\", \"requirements.txt\"],\n",
    "        check=True\n",
    "    )\n",
    "    print(\"Dependencies installed successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "v34dpxd5699",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import dependencies\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.agents import create_agent\n",
    "from langchain.tools import tool\n",
    "import json\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ghyykmt1p3u",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Firecrawl API Key: Set\n",
      "RunPod Endpoint: Set\n"
     ]
    }
   ],
   "source": [
    "# Environment variables\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# Load from .env file if it exists\n",
    "env_file = Path(\".env\")\n",
    "if env_file.exists():\n",
    "    with open(env_file) as f:\n",
    "        for line in f:\n",
    "            line = line.strip()\n",
    "            if line and not line.startswith('#') and '=' in line:\n",
    "                key, value = line.split('=', 1)\n",
    "                os.environ[key] = value\n",
    "\n",
    "# RunPod Pod endpoint (get from: https://www.runpod.io/console/pods)\n",
    "# Deploy a pod with vLLM template and GPT-OSS 20B model\n",
    "RUNPOD_ENDPOINT_URL = os.getenv(\"RUNPOD_ENDPOINT_URL\", \"YOUR_RUNPOD_ENDPOINT_HERE\")\n",
    "RUNPOD_API_KEY = os.getenv(\"RUNPOD_API_KEY\", \"YOUR_RUNPOD_API_KEY_HERE\")\n",
    "\n",
    "# Firecrawl API (get from: https://www.firecrawl.dev/)\n",
    "FIRECRAWL_API_KEY = os.getenv(\"FIRECRAWL_API_KEY\", \"YOUR_FIRECRAWL_API_KEY_HERE\")\n",
    "\n",
    "print(f\"Firecrawl API Key: {'Set' if FIRECRAWL_API_KEY != 'YOUR_FIRECRAWL_API_KEY_HERE' else 'Not set'}\")\n",
    "print(f\"RunPod Endpoint: {'Set' if RUNPOD_ENDPOINT_URL != 'YOUR_RUNPOD_ENDPOINT_HERE' else 'Not set'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ju945kyosq",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected to Firecrawl MCP server\n",
      "Available tools: ['firecrawl_scrape', 'firecrawl_map', 'firecrawl_search', 'firecrawl_crawl', 'firecrawl_check_crawl_status', 'firecrawl_extract']\n"
     ]
    }
   ],
   "source": [
    "# Connect to Firecrawl MCP Server using LangChain MCP Adapters\n",
    "from langchain_mcp_adapters.client import MultiServerMCPClient\n",
    "\n",
    "# Configure Firecrawl MCP server\n",
    "mcp_client = MultiServerMCPClient({\n",
    "    \"firecrawl\": {\n",
    "        \"transport\": \"stdio\",\n",
    "        \"command\": \"npx\",\n",
    "        \"args\": [\"-y\", \"firecrawl-mcp\"]\n",
    "    }\n",
    "})\n",
    "\n",
    "# Get tools from MCP server\n",
    "# Note: Jupyter notebooks have a running event loop, so we use await directly\n",
    "firecrawl_tools = await mcp_client.get_tools()\n",
    "\n",
    "print(f\"Connected to Firecrawl MCP server\")\n",
    "print(f\"Available tools: {[tool.name for tool in firecrawl_tools]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0831he4e27ua",
   "metadata": {},
   "source": [
    "# Real-Time Research Agent Demo\n",
    "\n",
    "This notebook demonstrates a LangChain v1 agent powered by vLLM and Firecrawl MCP tools for live web research."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "x8tjvc75lfj",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected to RunPod pod\n",
      "Test response: Hello from vLLM! I am here to assist you with any questions or tasks you may have.\n"
     ]
    }
   ],
   "source": [
    "# Initialize vLLM on RunPod Pod\n",
    "from langchain_openai import ChatOpenAI\n",
    "from pydantic import SecretStr\n",
    "\n",
    "if RUNPOD_ENDPOINT_URL == \"YOUR_RUNPOD_ENDPOINT_HERE\":\n",
    "    raise ValueError(\n",
    "        \"RunPod endpoint not configured. Please:\\n\"\n",
    "        \"1. Deploy a RunPod pod with PyTorch template\\n\"\n",
    "        \"2. Install vLLM and start server with Hermes-2-Pro-Mistral-7B\\n\"\n",
    "        \"3. Add RUNPOD_ENDPOINT_URL and RUNPOD_API_KEY to .env file\"\n",
    "    )\n",
    "\n",
    "# LangChain v1 / Modern OpenAI SDK parameters\n",
    "# REDUCED TOKENS: Model has 4096 token context limit\n",
    "llm = ChatOpenAI(\n",
    "    api_key=SecretStr(RUNPOD_API_KEY),\n",
    "    base_url=RUNPOD_ENDPOINT_URL,\n",
    "    model=\"Qwen/Qwen3-8B\",\n",
    "    max_completion_tokens=2048,  # Balanced for tool calls + responses\n",
    "    temperature=0.7\n",
    ")\n",
    "\n",
    "print(\"Connected to RunPod pod\")\n",
    "\n",
    "# Test the connection\n",
    "try:\n",
    "    response = llm.invoke(\"Say 'Hello from vLLM!' in one sentence.\")\n",
    "    print(f\"Test response: {response.content}\")\n",
    "except Exception as e:\n",
    "    print(f\"Connection test failed: {e}\")\n",
    "    print(\"The model may still be loading. Wait a few minutes and try again.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5legd0lb544",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agent created successfully!\n",
      "Tools available: ['firecrawl_scrape', 'firecrawl_map', 'firecrawl_search', 'firecrawl_crawl', 'firecrawl_check_crawl_status', 'firecrawl_extract']\n",
      "\n",
      "Agent test response:\n",
      "Please provide a specific topic or question you'd like me to research using firecrawl_search and firecrawl_scrape. For example, you could ask, \"What are the top AI companies in 2023?\" or \"Find research papers on AI published in 2023.\"\n"
     ]
    }
   ],
   "source": [
    "# Create the agent using LangChain v1\n",
    "\n",
    "# Shortened system prompt to save tokens (4096 token context limit)\n",
    "system_prompt = \"\"\"You are a research assistant. Use firecrawl_search to find information and firecrawl_scrape for details. Be concise.\"\"\"\n",
    "\n",
    "# Create agent - pass only essential tools\n",
    "agent = create_agent(\n",
    "    model=llm,\n",
    "    tools=firecrawl_tools,\n",
    "    system_prompt=system_prompt\n",
    ")\n",
    "\n",
    "print(\"Agent created successfully!\")\n",
    "print(f\"Tools available: {[tool.name for tool in firecrawl_tools]}\")\n",
    "\n",
    "# Quick test (MCP tools require async)\n",
    "test_response = await agent.ainvoke({\n",
    "    \"messages\": [{\"role\": \"user\", \"content\": \"What can you help me research?\"}]\n",
    "})\n",
    "\n",
    "print(\"\\nAgent test response:\")\n",
    "print(test_response[\"messages\"][-1].content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "o4dxg7ozm9j",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agent Response:\n",
      "Here's a quick snapshot of notable AI governance headlines from the past week in India and why they matter:\n",
      "\n",
      "1. **\"India's AI Governance Guidelines: Their pro-innovation approach ...**\" ([LiveMint](https://www.livemint.com/opinion/online-views/india-ai-governance-guidelines-pro-innovation-approach-template-global-south-artificial-intelligence-safety-rules/amp-11762768770780.html))\n",
      "   - This article discusses how India's AI guidelines aim to balance technological advancement with societal safeguards, grounded in pro-innovation principles.\n",
      "\n",
      "2. **\"What govt's AI guidelines mean for tech regulation in India\" ([The Indian Express](https://indianexpress.com/article/explained/explained-sci-tech/what-govts-ai-guidelines-mean-for-tech-regulation-10357983/))\n",
      "   - The article explains that the recent guidelines suggest risk management within the existing framework of laws under the guiding principle of 'Do No Harm'.\n",
      "\n",
      "3. **\"PM launches Rs 1 Lakh Crore Research, Development and ...**\" ([DST](https://dst.gov.in/pm-launches-rs-1-lakh-crore-research-development-and-innovation-scheme))\n",
      "   - This news is about the Prime Minister of India launching a Rs 1 Lakh Crore Research, Development, and Innovation Scheme, with a focus on AI under the India AI Mission.\n",
      "\n",
      "4. **\"India unveils game-changer AI governance guidelines\"** ([Economic Times](https://m.economictimes.com/ai/ai-insights/india-unveils-game-changer-ai-governance-guidelines-what-every-business-must-know/articleshow/125265894.cms))\n",
      "   - This article highlights the release of AI governance guidelines by India, marking a critical milestone in promoting safe, inclusive, and ethically aligned AI development.\n",
      "\n",
      "5. **\"3 in 4 developers in India are learning AI skills on their own: report\"** ([CXOtoday](https://cxotoday.com/news-analysis/3-in-4-developers-in-india-are-learning-ai-skills-on-their-own-report/))\n",
      "   - The article points out that 3 out of 4 developers in India are learning AI skills on their own, according to an IBM report. It also notes that many organizations are bypassing AI governance for a do-it-now AI adoption.\n",
      "\n",
      "These headlines matter because they indicate India's proactive approach to AI development and regulation, ensuring responsible and equitable adoption of AI technologies. The investment in AI research and development, along with the guidelines for AI governance, showcase the country's commitment to maintaining a balance between innovation and societal well-being.\n"
     ]
    }
   ],
   "source": [
    "# Demo 1: Live snapshot\n",
    "response = await agent.ainvoke({\n",
    "    \"messages\": [\n",
    "        {\"role\": \"user\", \"content\": \"Give me a quick snapshot of notable AI governance headlines from the past week in India. Highlight why they matter.\"}\n",
    "    ]\n",
    "})\n",
    "\n",
    "print(\"Agent Response:\")\n",
    "print(response[\"messages\"][-1].content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain-vllm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
